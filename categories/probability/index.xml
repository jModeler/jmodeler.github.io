<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Probability on The Journeyman Modeler</title><link>http://jmodeler.github.io/categories/probability/</link><description>Recent content in Probability on The Journeyman Modeler</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 14 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://jmodeler.github.io/categories/probability/index.xml" rel="self" type="application/rss+xml"/><item><title>Distribution Of The Negative of A Normally Distributed Random Variable</title><link>http://jmodeler.github.io/posts/negative-normal-rv/</link><pubDate>Mon, 14 Apr 2025 00:00:00 +0000</pubDate><guid>http://jmodeler.github.io/posts/negative-normal-rv/</guid><description>&lt;p&gt;This post derives the distribution for an random variable that appears in the derivation of a &lt;a href="https://jmodeler.github.io/posts/2025-04-26-sample-size-and-effect-size/" class="external-link" target="_blank" rel="noopener"&gt;result in another post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this post, I derive the distribution of the negative of a normally distributed random variable. Let&amp;rsquo;s say we have &lt;code&gt;\(X \sim N(\mu, \sigma^2)\)&lt;/code&gt;, and we want to find the distribution of &lt;code&gt;\(Y=-X\)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I start with the identity:
&lt;code&gt;\begin{align} P(Y \le y) = P(-X \le y) = P(X \ge -y) = 1 - P(X \le -y) \end{align}&lt;/code&gt;&lt;/p&gt;</description></item><item><title>Distribution of the Sample Mean of IID Normal Random Variables</title><link>http://jmodeler.github.io/posts/distribution-sample-mean/</link><pubDate>Mon, 14 Apr 2025 00:00:00 +0000</pubDate><guid>http://jmodeler.github.io/posts/distribution-sample-mean/</guid><description>&lt;p&gt;In this post I derive a result that will be used in &lt;a href="https://jmodeler.github.io/posts/2025-04-26-sample-size-and-effect-size/" class="external-link" target="_blank" rel="noopener"&gt;another post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Say we have Independent and Identically Distributed (IID) Normal random variables &lt;code&gt;\(X_i \sim N(\mu, \sigma^2)\)&lt;/code&gt;, and we have&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\begin{align} \bar{X} = \frac{1}{n}\sum^{n}_{i=1} X_i \end{align}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We want the distribution of &lt;code&gt;\(\bar{X}\)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;From a &lt;a href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables" class="external-link" target="_blank" rel="noopener"&gt;standard result&lt;/a&gt;, &lt;code&gt;\(\bar{X}\)&lt;/code&gt; is also Normally distributed. Once we have the mean and variance of &lt;code&gt;\(\bar{X}\)&lt;/code&gt;, we can completely specify its distribution.&lt;/p&gt;
&lt;p&gt;For the mean of &lt;code&gt;\(\bar{X}\)&lt;/code&gt;, note that &lt;code&gt;\(E(X_i) = \mu\)&lt;/code&gt; we then have:
&lt;code&gt;\begin{align} E(\bar{X}) = &amp;amp; \frac{1}{n} E\left(\sum^{n}_{i=1} X_i \right) \\ = &amp;amp; \frac{1}{n} \left(\sum^{n}_{i=1} E(X_i) \right) \\ = &amp;amp; \frac{1}{n} n\mu = \mu \end{align}&lt;/code&gt;&lt;/p&gt;</description></item></channel></rss>