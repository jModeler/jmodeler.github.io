<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Math on The Journeyman Modeler</title><link>http://jmodeler.github.io/categories/math/</link><description>Recent content in Math on The Journeyman Modeler</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 14 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://jmodeler.github.io/categories/math/index.xml" rel="self" type="application/rss+xml"/><item><title>Distribution Of The Negative of A Normally Distributed Random Variable</title><link>http://jmodeler.github.io/posts/negative-normal-rv/</link><pubDate>Mon, 14 Apr 2025 00:00:00 +0000</pubDate><guid>http://jmodeler.github.io/posts/negative-normal-rv/</guid><description>&lt;p>This post derives the distribution for an random variable that appears in the derivation of a &lt;a href="https://jmodeler.github.io/posts/2025-04-26-sample-size-and-effect-size/" class="external-link" target="_blank" rel="noopener">result in another post&lt;/a>.&lt;/p>
&lt;p>In this post, I derive the distribution of the negative of a normally distributed random variable. Let&amp;rsquo;s say we have &lt;code>\(X \sim N(\mu, \sigma^2)\)&lt;/code>, and we want to find the distribution of &lt;code>\(Y=-X\)&lt;/code>.&lt;/p>
&lt;p>I start with the identity:
&lt;code>\begin{align} P(Y \le y) = P(-X \le y) = P(X \ge -y) = 1 - P(X \le -y) \end{align}&lt;/code>&lt;/p></description></item><item><title>Distribution of the Sample Mean of IID Normal Random Variables</title><link>http://jmodeler.github.io/posts/distribution-sample-mean/</link><pubDate>Mon, 14 Apr 2025 00:00:00 +0000</pubDate><guid>http://jmodeler.github.io/posts/distribution-sample-mean/</guid><description>&lt;p>In this post I derive a result that will be used in &lt;a href="https://jmodeler.github.io/posts/2025-04-26-sample-size-and-effect-size/" class="external-link" target="_blank" rel="noopener">another post&lt;/a>.&lt;/p>
&lt;p>Say we have Independent and Identically Distributed (IID) Normal random variables &lt;code>\(X_i \sim N(\mu, \sigma^2)\)&lt;/code>, and we have&lt;/p>
&lt;p>&lt;code>\begin{align} \bar{X} = \frac{1}{n}\sum^{n}_{i=1} X_i \end{align}&lt;/code>&lt;/p>
&lt;p>We want the distribution of &lt;code>\(\bar{X}\)&lt;/code>.&lt;/p>
&lt;p>From a &lt;a href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables" class="external-link" target="_blank" rel="noopener">standard result&lt;/a>, &lt;code>\(\bar{X}\)&lt;/code> is also Normally distributed. Once we have the mean and variance of &lt;code>\(\bar{X}\)&lt;/code>, we can completely specify its distribution.&lt;/p>
&lt;p>For the mean of &lt;code>\(\bar{X}\)&lt;/code>, note that &lt;code>\(E(X_i) = \mu\)&lt;/code> we then have:
&lt;code>\begin{align} E(\bar{X}) = &amp;amp; \frac{1}{n} E\left(\sum^{n}_{i=1} X_i \right) \\ = &amp;amp; \frac{1}{n} \left(\sum^{n}_{i=1} E(X_i) \right) \\ = &amp;amp; \frac{1}{n} n\mu = \mu \end{align}&lt;/code>&lt;/p></description></item><item><title>A Summation Formula</title><link>http://jmodeler.github.io/posts/a-summation-formula/</link><pubDate>Mon, 07 Apr 2025 00:00:00 +0000</pubDate><guid>http://jmodeler.github.io/posts/a-summation-formula/</guid><description>&lt;p>This post derives a closed form solution for particular sum that appears in the derivation of a result in &lt;a href="https://jmodeler.github.io/posts/distribution-sample-mean/" class="external-link" target="_blank" rel="noopener">another post&lt;/a>.&lt;/p>
&lt;p>Say we have real numbers &lt;code>\(X_i\)&lt;/code> such that
&lt;code>\begin{align} X_i = x \,\, \forall i \tag{1} \end{align}&lt;/code>&lt;/p>
&lt;p>And we want to find the sum
&lt;code>\begin{align} \mathop{\sum\sum}_{\substack{i \ne j}} X_i X_j \,\,\,\, i,j \in {1, 2, \dots , n} \tag{2} \end{align}&lt;/code>&lt;/p>
&lt;p>From (1), the sum in (2) boils down to:
&lt;code>\begin{align} \mathop{\sum\sum}_{\substack{i \ne j}} x^2 \tag{3} \end{align}&lt;/code>&lt;/p></description></item></channel></rss>