<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts | The Journeyman Modeler</title><link>https://jmodeler.github.io/post/</link><atom:link href="https://jmodeler.github.io/post/index.xml" rel="self" type="application/rss+xml"/><description>Posts</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 12 Apr 2023 00:00:00 +0000</lastBuildDate><image><url>https://jmodeler.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Posts</title><link>https://jmodeler.github.io/post/</link></image><item><title>Resolving Errors When Loading the lldb Debugger</title><link>https://jmodeler.github.io/post/resolving-errors-when-loading-the-lldb-debugger/</link><pubDate>Wed, 12 Apr 2023 00:00:00 +0000</pubDate><guid>https://jmodeler.github.io/post/resolving-errors-when-loading-the-lldb-debugger/</guid><description>
&lt;p>From time to time, I work with &lt;span class="math inline">\(\texttt{C}\)&lt;/span> code, and I use the &lt;code>lldb&lt;/code> debugger to step through the code. Recently, after a Mac OS update, I started seeing this error when attempting to start the lldb debugger in terminal:&lt;/p>
&lt;pre>&lt;code>$ lldb
Traceback (most recent call last):
File &amp;quot;&amp;lt;string&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
File &amp;quot;/usr/local/Cellar/llvm/15.0.7_1/libexec/python3.11/site-packages/lldb/__init__.py&amp;quot;, line 96, in &amp;lt;module&amp;gt;
import six
ModuleNotFoundError: No module named &amp;#39;six&amp;#39;&lt;/code>&lt;/pre>
&lt;p>The error message says that a module (&lt;code>six&lt;/code>) is missing. The other issue, is that this module is missing on a version of python that is &lt;em>not&lt;/em> the global version set by &lt;code>pyenv&lt;/code>. I check the versions of pyenv on my system:&lt;/p>
&lt;pre>&lt;code>$ pyenv versions
system
* 3.8.16 (set by /Users/&amp;lt;username&amp;gt;/.pyenv/version)
3.9.1
3.11.2&lt;/code>&lt;/pre>
&lt;p>I’m guessing &lt;code>lldb&lt;/code> uses the &lt;code>system&lt;/code> version of Python. A simple &lt;code>pip3 install six&lt;/code> will not fix the issue, since this will install this package for Python &lt;code>3.8.16&lt;/code>, instead of the &lt;code>system&lt;/code> version. I now use &lt;code>pyenv&lt;/code> to set the local version of python to &lt;code>system&lt;/code>:&lt;/p>
&lt;pre>&lt;code>$ pyenv local system
$ pyenv versions
* system (set by /Users/sandeep/.python-version)
3.8.16
3.9.1
3.11.2&lt;/code>&lt;/pre>
&lt;p>I now install &lt;code>six&lt;/code>:&lt;/p>
&lt;pre>&lt;code>$ pip3 install six
Collecting six
Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)
Installing collected packages: six
Successfully installed six-1.16.0&lt;/code>&lt;/pre>
&lt;p>And I try launching &lt;code>lldb&lt;/code> on terminal again:&lt;/p>
&lt;pre>&lt;code>% lldb
(lldb)&lt;/code>&lt;/pre>
&lt;p>.. which takes me to the &lt;code>(lldb)&lt;/code> prompt without any issues.&lt;/p>
&lt;p>Make sure you “reset” the default python version to be used to the version you had before (in my case this would be version &lt;code>3.8.16&lt;/code>)&lt;/p></description></item><item><title>Resolving Install Errors for the lightweight_mmm Python Package</title><link>https://jmodeler.github.io/post/resolving-install-errors-for-the-lightweight-mmm-python-package/</link><pubDate>Sat, 25 Mar 2023 00:00:00 +0000</pubDate><guid>https://jmodeler.github.io/post/resolving-install-errors-for-the-lightweight-mmm-python-package/</guid><description>
&lt;p>To experiment with different specifications of a marketing mix model, I tried installing the &lt;a href="https://github.com/google/lightweight_mmm">lightweight_mmm&lt;/a> Python package from Google. When using the standard &lt;code>pip3 install lightweight_mmm&lt;/code> command in terminal, I was hitting this error:&lt;/p>
&lt;pre>&lt;code> × Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─&amp;gt; [66 lines of output]
The Meson build system
Version: 0.62.2
Source dir: /private/var/folders/ly/3d_s7td56qb7rn4qc2c6tmvm0000gn/T/pip-install-yc6ribm7/scipy_ae66ccfb8522422ab91e65b44570f273
Build dir: /private/var/folders/ly/3d_s7td56qb7rn4qc2c6tmvm0000gn/T/pip-install-yc6ribm7/scipy_ae66ccfb8522422ab91e65b44570f273/.mesonpy-ur2kyhcf/build
Build type: native build
Project name: SciPy
Project version: 1.9.1
C compiler for the host machine: cc (clang 14.0.0 &amp;quot;Apple clang version 14.0.0 (clang-1400.0.29.202)&amp;quot;)
C linker for the host machine: cc ld64 820.1
C++ compiler for the host machine: c++ (clang 14.0.0 &amp;quot;Apple clang version 14.0.0 (clang-1400.0.29.202)&amp;quot;)
C++ linker for the host machine: c++ ld64 820.1
Host machine cpu family: x86_64
Host machine cpu: x86_64
Compiler for C supports arguments -Wno-unused-but-set-variable: YES
Library m found: YES
Fortran compiler for the host machine: gfortran (gcc 8.2.0 &amp;quot;GNU Fortran (GCC) 8.2.0&amp;quot;)
Fortran linker for the host machine: gfortran ld64 820.1
Program cython found: YES (/private/var/folders/ly/3d_s7td56qb7rn4qc2c6tmvm0000gn/T/pip-build-env-gddbg9u0/overlay/bin/cython)
Program pythran found: YES (/private/var/folders/ly/3d_s7td56qb7rn4qc2c6tmvm0000gn/T/pip-build-env-gddbg9u0/overlay/bin/pythran)
Program cp found: YES (/bin/cp)
Program python found: YES (/Users/&amp;lt;username&amp;gt;/.pyenv/versions/3.11.2/bin/python3.11)
Found pkg-config: /usr/local/bin/pkg-config (0.29.2)
Library npymath found: YES
Library npyrandom found: YES
Found CMake: /usr/local/bin/cmake (3.26.0)
Run-time dependency openblas found: NO (tried pkgconfig, framework and cmake)
Run-time dependency openblas found: NO (tried pkgconfig, framework and cmake)
../../scipy/meson.build:130:0: ERROR: Dependency &amp;quot;OpenBLAS&amp;quot; not found, tried pkgconfig, framework and cmake&lt;/code>&lt;/pre>
&lt;p>I tried to install &lt;code>openblas&lt;/code> using homebrew, but it was already installed:&lt;/p>
&lt;pre>&lt;code>$ brew install openblas
==&amp;gt; Downloading https://formulae.brew.sh/api/formula.jws.json
######################################################################## 100.0%
==&amp;gt; Downloading https://formulae.brew.sh/api/cask.jws.json
Warning: openblas 0.3.21 is already installed and up-to-date.
To reinstall 0.3.21, run:
brew reinstall openblas&lt;/code>&lt;/pre>
&lt;p>So maybe the build process was failing because the compiler couldn’t find it on the system. On some searching, I found this &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/7906#issuecomment-1478618523">github issue&lt;/a> that discussed the same problem. Essentially, we get more information on &lt;code>openblas&lt;/code>, using &lt;code>brew info openblas&lt;/code> in the terminal which should show us this output:&lt;/p>
&lt;pre>&lt;code>==&amp;gt; openblas: stable 0.3.21 (bottled), HEAD [keg-only]
Optimized BLAS library
https://www.openblas.net/
/usr/local/Cellar/openblas/0.3.21 (23 files, 130MB)
Poured from bottle on 2023-02-11 at 08:52:47
From: https://github.com/Homebrew/homebrew-core/blob/HEAD/Formula/openblas.rb
License: BSD-3-Clause
==&amp;gt; Dependencies
Required: gcc ✔
==&amp;gt; Options
--HEAD
Install HEAD version
==&amp;gt; Caveats
openblas is keg-only, which means it was not symlinked into /usr/local,
because macOS provides BLAS in Accelerate.framework.
For compilers to find openblas you may need to set:
export LDFLAGS=&amp;quot;-L/usr/local/opt/openblas/lib&amp;quot;
export CPPFLAGS=&amp;quot;-I/usr/local/opt/openblas/include&amp;quot;
For pkg-config to find openblas you may need to set:
export PKG_CONFIG_PATH=&amp;quot;/usr/local/opt/openblas/lib/pkgconfig&amp;quot;
==&amp;gt; Analytics
install: 1,074 (30 days), 63,095 (90 days), 515,454 (365 days)
install-on-request: 171 (30 days), 10,278 (90 days), 85,564 (365 days)
build-error: 4 (30 days)&lt;/code>&lt;/pre>
&lt;p>In the output above, we find the options to be set for compilers to find &lt;code>openblas&lt;/code>. I run these commands in the terminal:&lt;/p>
&lt;pre>&lt;code>$ export LDFLAGS=&amp;quot;-L/usr/local/opt/openblas/lib&amp;quot;
$ export CPPFLAGS=&amp;quot;-I/usr/local/opt/openblas/include&amp;quot;
$ export PKG_CONFIG_PATH=&amp;quot;/usr/local/opt/openblas/lib/pkgconfig&amp;quot;&lt;/code>&lt;/pre>
&lt;p>I now try installing &lt;code>lightweight_mmm&lt;/code> using &lt;code>pip3 install lightweight_mmm&lt;/code> in the terminal, and this time the installation gets past the step it was failing, but runs for a long time and fails again:&lt;/p>
&lt;pre>&lt;code> Using cached scipy-1.6.1.tar.gz (27.3 MB)
Installing build dependencies ... done
Getting requirements to build wheel ... done
Preparing metadata (pyproject.toml) ... error
error: subprocess-exited-with-error
× Preparing metadata (pyproject.toml) did not run successfully.
│ exit code: 1
╰─&amp;gt; [119 lines of output]
setup.py:461: UserWarning: Unrecognized setuptools command (&amp;#39;dist_info --egg-base /private/var/folders/ly/3d_s7td56qb7rn4qc2c6tmvm0000gn/T/pip-modern-metadata-_yaq83ex&amp;#39;), proceeding with generating Cython sources and expanding templates
warnings.warn(&amp;quot;Unrecognized setuptools command (&amp;#39;{}&amp;#39;), proceeding with &amp;quot;
setup.py:563: DeprecationWarning:
`numpy.distutils` is deprecated since NumPy 1.23.0, as a result
of the deprecation of `distutils` itself. It will be removed for
Python &amp;gt;= 3.12. For older Python versions it will remain present.
It is recommended to use `setuptools &amp;lt; 60.0` for those Python versions.
For more details, see:
https://numpy.org/devdocs/reference/distutils_status_migration.html
from numpy.distutils.core import setup
Running from SciPy source directory.
INFO: lapack_opt_info:
INFO: lapack_armpl_info:
INFO: customize UnixCCompiler
INFO: libraries armpl_lp64_mp not found in [&amp;#39;/Users/&amp;lt;username&amp;gt;/.pyenv/versions/3.11.2/lib&amp;#39;, &amp;#39;/usr/local/lib&amp;#39;, &amp;#39;/usr/lib&amp;#39;]
INFO: NOT AVAILABLE
...&lt;/code>&lt;/pre>
&lt;p>On further searching, it appears &lt;a href="https://github.com/docker-library/python/issues/558">that the problem&lt;/a> could be the version of python I’m currently using (3.11.2).&lt;/p>
&lt;p>I tried using a version of Python &amp;lt; &lt;code>3.9&lt;/code> and checked if this was working. First, using the &lt;a href="https://jmodeler.github.io/post/setting-up-python-to-run-on-rmarkdown/">instructions here&lt;/a>, I used &lt;code>pyenv&lt;/code> to install version &lt;code>3.8.16&lt;/code>, with the &lt;code>--enable-shared&lt;/code> option:&lt;/p>
&lt;pre>&lt;code> $ env PYTHON_CONFIGURE_OPTS=&amp;quot;--enable-shared&amp;quot; pyenv install 3.8.16&lt;/code>&lt;/pre>
&lt;p>Next, I set this to be the global Python version&lt;/p>
&lt;pre>&lt;code> $ pyenv global 3.8.16&lt;/code>&lt;/pre>
&lt;p>I now try installing the package again using &lt;code>pip3 install lightweight_mmm&lt;/code>, and this time it works:&lt;/p>
&lt;pre>&lt;code>Installing collected packages: typing-extensions, tensorboard-plugin-wit, pytz, pyasn1, libclang, flatbuffers, zipp, wrapt, wheel, urllib3, tqdm, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, rsa, pyparsing, pyasn1-modules, protobuf, pillow, packaging, oauthlib, numpy, MarkupSafe, kiwisolver, keras, joblib, immutabledict, idna, grpcio, gast, fonttools, cycler, charset-normalizer, certifi, cachetools, absl-py, werkzeug, scipy, requests, python-dateutil, patsy, opt_einsum, multipledispatch, importlib-metadata, h5py, google-pasta, google-auth, contourpy, cftime, astunparse, scikit-learn, requests-oauthlib, pandas, netcdf4, matplotlib, markdown, jaxlib, jax, xarray, statsmodels, seaborn, numpyro, google-auth-oauthlib, tensorboard, arviz, tensorflow, lightweight_mmm
Running setup.py install for jax ... done
Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 arviz-0.11.2 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 cftime-1.6.2 charset-normalizer-3.1.0 contourpy-1.0.7 cycler-0.11.0 flatbuffers-23.3.3 fonttools-4.39.2 gast-0.4.0 google-auth-2.16.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 h5py-3.8.0 idna-3.4 immutabledict-2.2.3 importlib-metadata-6.1.0 jax-0.4.6 jaxlib-0.4.6 joblib-1.2.0 keras-2.11.0 kiwisolver-1.4.4 libclang-16.0.0 lightweight_mmm-0.1.7 markdown-3.4.3 matplotlib-3.6.1 multipledispatch-0.6.0 netcdf4-1.6.3 numpy-1.24.2 numpyro-0.11.0 oauthlib-3.2.2 opt_einsum-3.3.0 packaging-23.0 pandas-1.5.3 patsy-0.5.3 pillow-9.4.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2023.2 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 scikit-learn-1.2.2 scipy-1.10.1 seaborn-0.11.1 six-1.16.0 statsmodels-0.13.5 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.1 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0 threadpoolctl-3.1.0 tqdm-4.65.0 typing-extensions-3.10.0.2 urllib3-1.26.15 werkzeug-2.2.3 wheel-0.40.0 wrapt-1.15.0 xarray-2023.1.0 zipp-3.15.0&lt;/code>&lt;/pre>
&lt;p>While searching for a fix, I found &lt;a href="https://pyreadiness.org/3.9/">this website&lt;/a> that looks at Python 3.9 support for the 360 most downloaded packages on &lt;a href="https://pyreadiness.org/3.9/">PyPi&lt;/a>. This is a great reference to understand which packages (of the top 360) still do not support Python 3.9 (or later versions).&lt;/p></description></item><item><title>Resolving Errors when Creating Your First MineRL Agent</title><link>https://jmodeler.github.io/post/resolving-errors-when-creating-your-first-minerl-agent/</link><pubDate>Thu, 23 Mar 2023 00:00:00 +0000</pubDate><guid>https://jmodeler.github.io/post/resolving-errors-when-creating-your-first-minerl-agent/</guid><description>
&lt;p>In this post, I lay out the steps to follow to resolve the errors you see when creating your &lt;a href="https://minerl.readthedocs.io/en/latest/tutorials/first_agent.html">first MineRL agent&lt;/a> on a macOS. This is a continuation of &lt;a href="https://jmodeler.github.io/post/resolving-install-errors-with-minerl/">this post&lt;/a>, which looks at resolving install errors on the &lt;code>minerl&lt;/code> package.&lt;/p>
&lt;p>I borrow heavily from &lt;a href="https://github.com/minerllabs/minerl/issues/659#issuecomment-1306635414">this github issue comment&lt;/a>.&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>Clone the repository using the terminal command below&lt;/p>
&lt;pre>&lt;code> git clone https://github.com/minerllabs/minerl.git&lt;/code>&lt;/pre>
&lt;p>This will create a &lt;code>minerl&lt;/code> directory. Make sure that the path to the cloned repository does not have spaces in it (i.e. the path should &lt;strong>not&lt;/strong> be &lt;code>/Users/&amp;lt;username&amp;gt;/minerl folder/minerl&lt;/code> – you will get &lt;code>file not found&lt;/code> errors in the next few steps otherwise)&lt;/p>&lt;/li>
&lt;li>&lt;p>Open the patch file in the directory &lt;code>minerl/scripts/mcp_patch.diff&lt;/code>, and replace version number &lt;code>3.2.1&lt;/code> to &lt;code>3.3.1&lt;/code> for &lt;code>lwjgl-opengl&lt;/code> (&lt;a href="https://github.com/minerllabs/minerl/blob/03510486957633676d269bf83115a84499ef7f47/scripts/mcp_patch.diff#L314">github link&lt;/a> to part of the file where the version number should be replaced)&lt;/p>&lt;/li>
&lt;li>&lt;p>From inside the &lt;code>minerl&lt;/code> folder on terminal, run the following command:&lt;/p>
&lt;pre>&lt;code> pip3 install .&lt;/code>&lt;/pre>&lt;/li>
&lt;li>&lt;p>If the installation fails, please go to this &lt;a href="https://jmodeler.github.io/post/resolving-install-errors-with-minerl/">post&lt;/a> and see if the steps outlined there can help.&lt;/p>&lt;/li>
&lt;li>&lt;p>If the installation is successful, navigate to the &lt;code>minerl/minerl/MCP-Reborn&lt;/code> folder and open the &lt;code>launchClient.sh&lt;/code> file in a text editor of choice. Modify a line close to the end of the file that starts with &lt;code>Java ....&lt;/code>, so that the new line becomes:&lt;/p>
&lt;pre>&lt;code> java -Xmx$maxMem -XstartOnFirstThread -jar $fatjar --envPort=$port&lt;/code>&lt;/pre>&lt;/li>
&lt;li>&lt;p>Navigate to &lt;code>MCP-Reborn/src/main/java/net/minecraft/client/MainWindow.java&lt;/code>, and make the following changes:&lt;/p>
&lt;ul>
&lt;li>&lt;p>Comment out the following line (add a &lt;code>//&lt;/code> to the left of this line)&lt;/p>
&lt;pre>&lt;code> GLFW.glfwSetWindowIcon(this.handle, buffer);&lt;/code>&lt;/pre>&lt;/li>
&lt;li>&lt;p>Comment out the body of the &lt;code>checkGlfwError&lt;/code> method, it should look like this after commenting out the body:&lt;/p>
&lt;pre>&lt;code> public static void checkGlfwError(BiConsumer&amp;lt;Integer, String&amp;gt; glfwErrorConsumer) {
/* RenderSystem.assertThread(RenderSystem::isInInitPhase);
try (MemoryStack memorystack = MemoryStack.stackPush()) {
PointerBuffer pointerbuffer = memorystack.mallocPointer(1);
int i = GLFW.glfwGetError(pointerbuffer);
if (i != 0) {
long j = pointerbuffer.get();
String s = j == 0L ? &amp;quot;&amp;quot; : MemoryUtil.memUTF8(j);
glfwErrorConsumer.accept(i, s);
}
} */
}&lt;/code>&lt;/pre>
&lt;p>&lt;strong>DO NOT&lt;/strong> comment out/delete the method declaration, else the next step will fail.&lt;/p>&lt;/li>
&lt;/ul>&lt;/li>
&lt;li>&lt;p>Navigate to the &lt;code>minerl/minerl/MCP-Reborn&lt;/code> folder in terminal and rebuild &lt;code>MCP-Reborn&lt;/code> using the command below:&lt;/p>
&lt;pre>&lt;code> ./gradlew clean build shadowJar&lt;/code>&lt;/pre>
&lt;p>You should see a success message like the one below:
&lt;img src="build_success.png" alt="Build Success" />&lt;/p>&lt;/li>
&lt;li>&lt;p>Find the location where the &lt;code>minerl&lt;/code> package was installed. If you use &lt;code>pyenv&lt;/code> like I do, you can use the &lt;code>pyenv which python&lt;/code> command in terminal, to get the version of python being used by the system. For example, if the version number is &lt;code>3.11.2&lt;/code>, then the location of the &lt;code>minerl&lt;/code> package should be:&lt;/p>
&lt;pre>&lt;code> /Users/&amp;lt;username&amp;gt;/.pyenv/versions/3.11.2/lib/python3.11/site-packages/minerl&lt;/code>&lt;/pre>&lt;/li>
&lt;li>&lt;p>Navigate to the &lt;code>minerl&lt;/code> folder above, and replace the &lt;code>MCP-Reborn&lt;/code> folder in it with the &lt;code>MCP-Reborn&lt;/code> folder you just built in step 7 above.&lt;/p>&lt;/li>
&lt;li>&lt;p>Follow the steps to &lt;a href="https://minerl.readthedocs.io/en/latest/tutorials/first_agent.html">build your first agent&lt;/a>, this should work now and you should see something like this:
&lt;img src="first_agent_run.png" alt="First Agent" />&lt;/p>&lt;/li>
&lt;/ol></description></item><item><title>Resolving Install Errors with MineRL</title><link>https://jmodeler.github.io/post/resolving-install-errors-with-minerl/</link><pubDate>Wed, 22 Mar 2023 00:00:00 +0000</pubDate><guid>https://jmodeler.github.io/post/resolving-install-errors-with-minerl/</guid><description>
&lt;p>In this post, I’ll resolve an error that one might face when trying to install the &lt;code>minerl&lt;/code> Python package. The instructions to install this package can be &lt;a href="https://minerl.readthedocs.io/en/latest/tutorials/index.html">found here&lt;/a>.&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>Using the instructions above, when I used the install command (&lt;code>pip3 install git+https://github.com/minerllabs/minerl&lt;/code>), I got the following error (only the relevant part is shown here):&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> Note: Some input files use or override a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
Note: Some input files use unchecked or unsafe operations.
Note: Recompile with -Xlint:unchecked for details.
100 errors
only showing the first 100 errors, of 2866 total; use -Xmaxerrs if you would like to see more
&amp;gt; Task :compileJava FAILED
FAILURE: Build failed with an exception.
* What went wrong:
Execution failed for task &amp;#39;:compileJava&amp;#39;.
&amp;gt; Compilation failed; see the compiler error output for details.
* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.
* Get more help at https://help.gradle.org
Deprecated Gradle features were used in this build, making it incompatible with Gradle 7.0.
Use &amp;#39;--warning-mode all&amp;#39; to show the individual deprecation warnings.
See https://docs.gradle.org/6.8.1/userguide/command_line_interface.html#sec:command_line_warnings
BUILD FAILED in 21s
10 actionable tasks: 10 executed
Traceback (most recent call last):
File &amp;quot;&amp;lt;string&amp;gt;&amp;quot;, line 2, in &amp;lt;module&amp;gt;
File &amp;quot;&amp;lt;pip-setuptools-caller&amp;gt;&amp;quot;, line 34, in &amp;lt;module&amp;gt;
File &amp;quot;/private/var/folders/ly/3d_s7td56qb7rn4qc2c6tmvm0000gn/T/pip-req-build-9xj7s1on/setup.py&amp;quot;, line 214, in &amp;lt;module&amp;gt;
prep_mcp()
File &amp;quot;/private/var/folders/ly/3d_s7td56qb7rn4qc2c6tmvm0000gn/T/pip-req-build-9xj7s1on/setup.py&amp;quot;, line 198, in prep_mcp
subprocess.check_call(&amp;#39;{} clean build shadowJar&amp;#39;.format(gradlew).split(&amp;#39; &amp;#39;), cwd=workdir)
File &amp;quot;/Users/&amp;lt;username&amp;gt;/.pyenv/versions/3.11.2/lib/python3.11/subprocess.py&amp;quot;, line 413, in check_call
raise CalledProcessError(retcode, cmd)
subprocess.CalledProcessError: Command &amp;#39;[&amp;#39;./gradlew&amp;#39;, &amp;#39;clean&amp;#39;, &amp;#39;build&amp;#39;, &amp;#39;shadowJar&amp;#39;]&amp;#39; returned non-zero exit status 1.
[end of output]
note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed&lt;/code>&lt;/pre>
&lt;ol start="2" style="list-style-type: decimal">
&lt;li>Searching for the error message (&lt;code>error: metadata-generation-failed&lt;/code>) took me to a bunch of websites that provided other options to try:
&lt;ul>
&lt;li>From the &lt;a href="https://minerl.readthedocs.io/en/latest/tutorials/index.html">install page&lt;/a>, I tried providing the &lt;code>--user&lt;/code> option in the install command, that did not work, and I got the same error. This was the command I used: &lt;code>pip3 install git+https://github.com/minerllabs/minerl --user&lt;/code>&lt;/li>
&lt;li>From &lt;a href="https://stackoverflow.com/questions/74188013/python-pygame-not-installing">this stackoverflow page&lt;/a>, I used the &lt;code>--pre&lt;/code> option in the install command, that didn’t work either. This was the command I used: &lt;code>pip3 install git+https://github.com/minerllabs/minerl --pre&lt;/code>&lt;/li>
&lt;li>From &lt;a href="https://bobbyhadz.com/blog/python-error-metadata-generation-failed-encountered-error">this page&lt;/a>, I learnt about using the &lt;code>--use-deprecated&lt;/code> option, but that did not work too. This was the command I used: &lt;code>pip3 install git+https://github.com/minerllabs/minerl --use-deprecated=legacy-resolver&lt;/code>&lt;/li>
&lt;/ul>&lt;/li>
&lt;li>Going back to the &lt;code>minerl&lt;/code> &lt;a href="https://minerl.readthedocs.io/en/latest/tutorials/index.html">install page&lt;/a>, I checked the Java version, hoping that this was the issue:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> $ java -version
openjdk version &amp;quot;14.0.2&amp;quot; 2020-07-14
OpenJDK Runtime Environment (build 14.0.2+12-46)
OpenJDK 64-Bit Server VM (build 14.0.2+12-46, mixed mode, sharing)&lt;/code>&lt;/pre>
&lt;ol start="4" style="list-style-type: decimal">
&lt;li>My system was using the wrong version of Java (it should be using &lt;code>1.8._&lt;/code>)! I used the &lt;a href="https://gist.github.com/schnell18/bcb9833f725be22f6acd01f94b486392">instructions here&lt;/a>, to remove the other version of Java. These were the exact commands I used:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> $ sudo rm -fr /Library/Java/JavaVirtualMachines/openjdk-14.0.2.jdk/
$ sudo rm -fr /Library/Internet\ Plug-Ins/JavaAppletPlugin.plugin
$ sudo rm -fr /Library/PreferencePanes/JavaControlPanel.prefPane&lt;/code>&lt;/pre>
&lt;ol start="5" style="list-style-type: decimal">
&lt;li>If you encounter this error on a macOS, and the Java version is the cause, check your Java version using the &lt;code>java -version&lt;/code> command on terminal, and navigate to the &lt;code>/Library/Java/JavaVirtualMachines/&lt;/code> folder to find the other versions of Java on your machine. Then use the &lt;code>sudo&lt;/code> commands above to delete the appropriate folders. After deleting the other Java folder on my machine, typing &lt;code>java -version&lt;/code> in my terminal gave me the following result:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> $ java -version
openjdk version &amp;quot;1.8.0_292&amp;quot;
OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_292-b10)
OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.292-b10, mixed mode)&lt;/code>&lt;/pre>
&lt;ol start="6" style="list-style-type: decimal">
&lt;li>After doing this, the install command (&lt;code>pip3 install git+https://github.com/minerllabs/minerl&lt;/code>), worked fine on the terminal. I did see some error messages (around installation of the Python package &lt;code>gym&lt;/code>), but it didn’t appear to affect the installation:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> Failed to build gym
Installing collected packages: PyWavelets, Pyro4, opencv-python, matplotlib-inline, lxml,
jinja2, jedi, inflection, idna, humanfriendly, flaky, dill, decorator, cloudpickle, charset-normalizer,
certifi, asttokens, stack-data, requests, imagehash, gym, coloredlogs, ipython, minerl
Running setup.py install for gym ... done
DEPRECATION: gym was installed using the legacy &amp;#39;setup.py install&amp;#39;
method, because a wheel could not be built for it. pip 23.1 will enforce this behaviour change.
A possible replacement is to fix the wheel build issue reported above.
Discussion can be found at https://github.com/pypa/pip/issues/8368&lt;/code>&lt;/pre>
&lt;ol start="8" style="list-style-type: decimal">
&lt;li>Create your &lt;a href="https://minerl.readthedocs.io/en/latest/tutorials/first_agent.html">first agent&lt;/a> and check if everything is working properly. If the example linked does not work, refer to &lt;a href="https://jmodeler.github.io/post/resolving-errors-when-creating-your-first-minerl-agent/">this post&lt;/a>, or &lt;a href="https://github.com/minerllabs/minerl/issues/659#issuecomment-1306635414">this github issue comment&lt;/a>.&lt;/li>
&lt;/ol></description></item><item><title>Distributions with Thin and Fat Tails</title><link>https://jmodeler.github.io/post/distributions-with-thin-and-fat-tails/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://jmodeler.github.io/post/distributions-with-thin-and-fat-tails/</guid><description>
&lt;p>In this post, we’ll explore a key difference between thin and fat tailed distributions, and what this means in the world of insurance and risk management. These results are from Chapter 3 of &lt;span class="citation">Taleb (&lt;a href="#ref-taleb2020fattails" role="doc-biblioref">2020&lt;/a>)&lt;/span>.&lt;/p>
&lt;p>In the world of thin tails (i.e. data that are Gaussian distributed), as the sample of data gets larger, no single data point can change the properties of the entire sample (Taleb calls this “Mediocristan”). Conversely, in data from fat tailed distributions (i.e. data from a distribution whose tail decays like a &lt;a href="https://en.wikipedia.org/wiki/Power_law">power law&lt;/a>), a single data point (or rare events) can disproportionately impact the properties of a sample (Taleb calls this “Extremistan”). The next section explores data from a standard normal distribution, and how likely it is to observe a tail event in such data.&lt;/p>
&lt;div id="gaussian-data-mediocristan" class="section level2">
&lt;h2>Gaussian Data (Mediocristan)&lt;/h2>
&lt;p>&lt;strong>Summary:&lt;/strong> In data that are normally (Gaussian) distributed, it is more likely to observe several smaller “bad” events that one massive “tail” event. For insurability, the losses need to come from many smaller bad events than a single tail event. This is true in the case of Gaussian data.&lt;/p>
&lt;p>Taleb gives the example of checking the total height of two individuals randomly drawn from a sample of people (the heights are assumed to be normally distributed, or our sample is from Mediocristan). If the total height is 4.1m, (a tail event), it is more likely that the individual heights are 2.05m each than one being 10cm and the other being 4m.&lt;/p>
&lt;p>Mathematically stated, if &lt;span class="math inline">\(X\)&lt;/span> is a large value generated from a Gaussian distribution (Mediocristan), it is more likely to observe a value greater than this twice, than observing a random value that is greater than &lt;span class="math inline">\(2X\)&lt;/span>. Let us verify this by drawing a few sample values from the standard normal distribution.&lt;/p>
&lt;pre class="python">&lt;code>
import scipy.stats as dist
# standard normal distribution
st_norm = dist.norm(0,1)
# get the probability of observing a value that is more than 3 standard
# deviations away from the mean, i.e. 3
p_x = 1 - st_norm.cdf(3)
# get the probability of observing a value that is more than 6 = 3*2 standard
# deviations away from the mean
p_2x = 1 - st_norm.cdf(6)
# print the probability of values
print(&amp;quot;Probability of observing two values that are 3 standard deviations \n away from the mean: {0:.3E}&amp;quot;.format(p_x * p_x))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Probability of observing two values that are 3 standard deviations
## away from the mean: 1.822E-06&lt;/code>&lt;/pre>
&lt;pre class="python">&lt;code>print(&amp;quot;Probability of observing a single value that is 6 standard deviations \n away from the mean: {0:.3E}&amp;quot;.format(p_2x))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Probability of observing a single value that is 6 standard deviations
## away from the mean: 9.866E-10&lt;/code>&lt;/pre>
&lt;p>As expected, in the Gaussian world, it is more likely to observe a series of smaller tail events, than a single large tail event, that modifies the properties of the data sample. If these tail events are associated with losses, then for insurability, the losses need to come from many (smaller) events than a single (large) one, which leads to financial ruin. The formal conditions for this were discussed in &lt;span class="citation">Cramér (&lt;a href="#ref-cramer1959mathematical" role="doc-biblioref">1959&lt;/a>)&lt;/span>.&lt;/p>
&lt;/div>
&lt;div id="data-from-a-pareto-distribution-extremistan" class="section level2">
&lt;h2>Data from a Pareto Distribution (Extremistan)&lt;/h2>
&lt;p>&lt;strong>Summary:&lt;/strong> In data that are from &lt;a href="https://en.wikipedia.org/wiki/Heavy-tailed_distribution">subexponential distributions&lt;/a> (like the &lt;a href="https://en.wikipedia.org/wiki/Pareto_distribution">pareto&lt;/a>), it is more likely to observe one massive “tail” event than several smaller “bad” events. These are not insurable, since there is a risk of catastrophe.&lt;/p>
&lt;p>Let’s repeat the probability calculation exercise we did earlier, but now for the pareto distribution:&lt;/p>
&lt;pre class="python">&lt;code>
# set the shape parameter for the pareto distribution
b = 3
# get the pareto distribution object from dist, alias for scipy.stats
st_pareto = dist.pareto(b)
# get the probability of observing a value that is thrice the mean, i.e. 4.5
p_x = 1 - st_pareto.cdf(4.5)
# get the probability of observing a value that is 6 times the mean, i.e. 9
p_2x = 1 - st_pareto.cdf(9)
# print the probability of values
print(&amp;quot;Probability of observing two values that are thrice the mean: {0:.3E}&amp;quot;.format(p_x * p_x))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Probability of observing two values that are thrice the mean: 1.204E-04&lt;/code>&lt;/pre>
&lt;pre class="python">&lt;code>print(&amp;quot;Probability of observing a single value that is 6 times the mean: {0:.3E}&amp;quot;.format(p_2x))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Probability of observing a single value that is 6 times the mean: 1.372E-03&lt;/code>&lt;/pre>
&lt;p>Note that the &lt;code>pareto()&lt;/code> method in &lt;code>scipy&lt;/code> takes the shape parameter &lt;code>b&lt;/code> as input, as &lt;a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pareto.html">explained here&lt;/a>.&lt;/p>
&lt;p>As we can see, the probability of observing a single large tail event is higher than observing a series of smaller tail events. If large tail events are considered to be bad and lead to financial ruin, this makes such cases uninsurable.&lt;/p>
&lt;p>To drive the point home, Taleb gives another example of checking the total income of two individuals randomly drawn from a sample of people (the incomes are assumed to be subexponentially distributed, or our sample is from Extremistan). If the total income is &lt;code>$36 Million&lt;/code>, (a tail event), it is more likely that the individual incomes are &lt;code>$35,999,000&lt;/code> and &lt;code>$1000&lt;/code> than both incomes being &lt;code>$18 Million&lt;/code> each.&lt;/p>
&lt;/div>
&lt;div id="references" class="section level2 unnumbered">
&lt;h2>References&lt;/h2>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-cramer1959mathematical" class="csl-entry">
Cramér, Harald. 1959. &lt;em>On the Mathematical Theory of Risk&lt;/em>. Centraltryckeriet.
&lt;/div>
&lt;div id="ref-taleb2020fattails" class="csl-entry">
Taleb, Nassim Nicholas. 2020. &lt;span>“Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications.”&lt;/span> &lt;em>arXiv Preprint arXiv:2001.10488&lt;/em>.
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Setting up Python to Run on Rmarkdown</title><link>https://jmodeler.github.io/post/setting-up-python-to-run-on-rmarkdown/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://jmodeler.github.io/post/setting-up-python-to-run-on-rmarkdown/</guid><description>
&lt;p>I use the &lt;a href="https://github.com/wowchemy/starter-hugo-academic">Hugo academic template&lt;/a> along with Rstudio’s &lt;a href="https://github.com/rstudio/blogdown">Blogdown&lt;/a> package to generate and deploy this website to &lt;a href="https://pages.github.com/">github pages&lt;/a>. I use this setup to generate blog posts (via &lt;a href="https://rmarkdown.rstudio.com/">Rmarkdown&lt;/a>) that render &lt;span class="math inline">\(\LaTeX\)&lt;/span> math and output from R code.&lt;/p>
&lt;p>Sometimes, I’d like to run Python code inside Rmarkdown too, and this is &lt;a href="https://bookdown.org/yihui/rmarkdown-cookbook/eng-python.html">supported&lt;/a>, via the &lt;a href="https://cran.r-project.org/web/packages/reticulate/index.html">reticulate&lt;/a> package. That said, the following steps need to be followed to make sure everything runs smoothly (all of these steps worked on a macOS Ventura operating system)&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>In your Rmarkdown file, always have this code chunk to setup Python use for later:&lt;/li>
&lt;/ol>
&lt;pre class="r">&lt;code># setup for using python code later in the page
# import the reticulate package
library(reticulate)
# specify the version of python to use
use_python(&amp;quot;/Users/&amp;lt;username&amp;gt;/.pyenv/shims/python&amp;quot;)&lt;/code>&lt;/pre>
&lt;ol start="2" style="list-style-type: decimal">
&lt;li>&lt;p>Note: In the chunk above, replace &lt;code>&amp;lt;username&amp;gt;&lt;/code> with your username. In addition, I use &lt;code>pyenv&lt;/code> to manage python versions on my system, as &lt;a href="https://blog.teclado.com/how-to-use-pyenv-manage-python-versions/">explained here&lt;/a>. If you don’t have &lt;code>pyenv&lt;/code> already, be sure to set it up using the instructions in the previous link.&lt;/p>&lt;/li>
&lt;li>&lt;p>You might hit an error when you run a python code chunk in Rmarkdown:&lt;/p>&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> Error: &amp;#39;/Users/&amp;lt;username&amp;gt;/.pyenv/shims/python&amp;#39; was not built with a shared library.
reticulate can only bind to copies of Python built with &amp;#39;--enable-shared&amp;#39;.
Execution halted
Error : Failed to render content/post/&amp;lt;name_of_post&amp;gt;/index.en.Rmd&lt;/code>&lt;/pre>
&lt;ol start="4" style="list-style-type: decimal">
&lt;li>&lt;p>This just means I must build a version of python with the &lt;code>--enable-shared&lt;/code> flag. I do this using &lt;code>pyenv&lt;/code>.&lt;/p>&lt;/li>
&lt;li>&lt;p>First, choose a version of python that you want to use. You can do this by going to the terminal and typing&lt;/p>&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> pyenv install --list&lt;/code>&lt;/pre>
&lt;ol start="6" style="list-style-type: decimal">
&lt;li>This should show you a long output, some of them will be python versions, as shown below:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> ...
3.10.1
3.10.2
3.10.3
3.10.4
3.10.5
3.10.6
3.10.7
3.10.8
3.10.9
3.10.10
3.11.0
...
&lt;/code>&lt;/pre>
&lt;ol start="7" style="list-style-type: decimal">
&lt;li>Choose an appropriate version and use the command below to install said version, like so (in the example below, I choose to install 3.11.0):&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> env PYTHON_CONFIGURE_OPTS=&amp;quot;--enable-shared&amp;quot; pyenv install 3.11.0&lt;/code>&lt;/pre>
&lt;ol start="8" style="list-style-type: decimal">
&lt;li>In the previous step, note the &lt;code>--enable-shared&lt;/code> option has now been added&lt;/li>
&lt;li>We now want to set this Python version to be the global Python version. Type the following command (replace 3.11.0 in the command below with the version you installed):&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> pyenv global 3.11.0&lt;/code>&lt;/pre>
&lt;ol start="10" style="list-style-type: decimal">
&lt;li>You can also check if the global version set is the correct version using the following command:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> pyenv versions&lt;/code>&lt;/pre>
&lt;ol start="10" style="list-style-type: decimal">
&lt;li>&lt;p>If you’re using python packages (i.e. &lt;code>numpy&lt;/code>, &lt;code>pandas&lt;/code>, etc.) in your code chunks, make sure to install them first (i.e. by using &lt;code>pip3 install numpy&lt;/code>, &lt;code>pip3 install pandas&lt;/code>, etc. in the terminal)&lt;/p>&lt;/li>
&lt;li>&lt;p>With all of this set up, you should no longer see the error above when you knit Rmarkdown documents with Python code chunks in them.&lt;/p>&lt;/li>
&lt;/ol></description></item><item><title>Numerical Integration with Sparse Grids</title><link>https://jmodeler.github.io/post/numerical-integration-with-sparse-grids/</link><pubDate>Mon, 20 Mar 2023 00:00:00 +0000</pubDate><guid>https://jmodeler.github.io/post/numerical-integration-with-sparse-grids/</guid><description>
&lt;p>I recently read a paper &lt;span class="citation">(&lt;a href="#ref-heiss2008likelihood" role="doc-biblioref">Heiss and Winschel 2008&lt;/a>)&lt;/span> that advocated the use of certain techniques (Sparse Grids, SG henceforth) in numerical integration to calculate likelihood functions, as opposed to using Monte Carlo (MC henceforth) methods for the same. While approximating integrals with MC methods are simpler to implement, they might lead to integral values with considerable simulation error &lt;span class="citation">(&lt;a href="#ref-skrainka2011high" role="doc-biblioref">Skrainka and Judd 2011&lt;/a>)&lt;/span>. This post attempts to demonstrate the claim in &lt;span class="citation">Skrainka and Judd (&lt;a href="#ref-skrainka2011high" role="doc-biblioref">2011&lt;/a>)&lt;/span> using two very simple integrals, to which we already know the value. I attempt to compare the outcomes from using MC and SG.&lt;/p>
&lt;p>The integrals I’ll be evaluating are:&lt;/p>
&lt;p>&lt;span class="math display" id="eq:sumint">\[\begin{equation}
\int_{-\infty}^{\infty} \left( \sum_{i=1}^{5} x_i \right) dF_{X} \tag{1}
\end{equation}\]&lt;/span>&lt;/p>
&lt;p>and
&lt;span class="math display" id="eq:prodint">\[\begin{equation}
\int_{-\infty}^{\infty} \left( \prod_{i=1}^{5} x_i^2 \right) dF_{X} \tag{2}
\end{equation}\]&lt;/span>&lt;/p>
&lt;p>where &lt;span class="math inline">\(X = \{x_i\}_{i=1}^{5}\)&lt;/span> is a five dimensional random variable, which is distributed according to the multivariate standard normal:
&lt;span class="math display">\[
X \sim N\left( \left[ \begin{array}
{r}
0 \\
0 \\
0 \\
0 \\
0 \\
\end{array}\right], \left[ \begin{array}
{rrrrr}
1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\
\end{array}\right] \right)
\]&lt;/span>&lt;/p>
&lt;p>Given the distribution of &lt;span class="math inline">\(X\)&lt;/span>, the values of the integrals above are easily obtained from standard results (the value of &lt;a href="#eq:sumint">(1)&lt;/a> is &lt;span class="math inline">\(0\)&lt;/span> and that of &lt;a href="#eq:prodint">(2)&lt;/a> is &lt;span class="math inline">\(1\)&lt;/span>) respectively.&lt;/p>
&lt;p>I write some utility functions in R to compute the integrands above:&lt;/p>
&lt;pre class="r">&lt;code>#function to compute the sum of components of the random vector
s &amp;lt;- function(x)
{
return(sum(x))
}
#function to compute the square product of the components of the random vector
p &amp;lt;- function(x)
{
return(prod(x^2))
}&lt;/code>&lt;/pre>
&lt;p>I now write a function that:&lt;/p>
&lt;ul>
&lt;li>Simulates a certain number of draws from the distribution of the random variable &lt;span class="math inline">\(X\)&lt;/span>&lt;/li>
&lt;li>Computes the integrand function using each of these draws as input&lt;/li>
&lt;li>Takes the average of the values computed in the previous step&lt;/li>
&lt;/ul>
&lt;p>This function, in effect, would give us the approximate value of the integral via MC methodology.&lt;/p>
&lt;p>The code is provided below, note that I use the &lt;tt>&lt;a href="https://cran.r-project.org/web/packages/mvtnorm/index.html">mvtnorm&lt;/a>&lt;/tt> package to create random draws.&lt;/p>
&lt;pre class="r">&lt;code>library(mvtnorm)
#Function to calculate the MC approximation for the integral
mc_int &amp;lt;- function(s, n, mu, sigma)
{
#generate random draws
x &amp;lt;- rmvnorm(n, mean = mu, sigma = sigma)
#now get the integral
mc_int_n &amp;lt;- mean(apply(x, 1, s))
return(mc_int_n)
}
set.seed(100)
n &amp;lt;- 1000
mc_val &amp;lt;- mc_int(s, n, mu = rep(0,5), sigma = diag(5))
mc_val&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 0.007150433&lt;/code>&lt;/pre>
&lt;p>The result, 0.00715 is not far off from the true value of &lt;span class="math inline">\(0\)&lt;/span> at first glance, however, we need to compare this to the result from the SG approach.&lt;/p>
&lt;p>R has a package that generates sparse grids for numerical integration as described in &lt;span class="citation">Heiss and Winschel (&lt;a href="#ref-heiss2008likelihood" role="doc-biblioref">2008&lt;/a>)&lt;/span>, called &lt;tt>&lt;a href="https://cran.r-project.org/web/packages/SparseGrid/index.html">SparseGrid&lt;/a>&lt;/tt>. We now use the nodes and weights generated from this package to approximate the first integral.
I re-use some of the code provided in the documentation for the &lt;tt>&lt;a href="https://cran.r-project.org/web/packages/SparseGrid/vignettes/SparseGrid.pdf">SparseGrid&lt;/a>&lt;/tt> package in R.&lt;/p>
&lt;pre class="r">&lt;code>library(SparseGrid)
#generate sparse grids for a 5 dimensional RV with accuracy level 2
sg &amp;lt;- createSparseGrid(type=&amp;#39;KPN&amp;#39;, dimension=5, k=2)
sg_int &amp;lt;- function(func, sg, ...)
{
gx &amp;lt;- apply(sg$nodes, 1, function(x) {func(x, ...)})
return(sum(gx * sg$weights))
}
sg_val &amp;lt;- sg_int(s, sg)
sg_val&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 0&lt;/code>&lt;/pre>
&lt;p>The result here is exactly 0. In light of this finding, the value obtained from the MC approach, in comparison, is a little off, and tends to show a high variance in output:&lt;/p>
&lt;pre class="r">&lt;code>set.seed(100)
mc_int(s, n, mu = rep(0,5), sigma = diag(5))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 0.007150433&lt;/code>&lt;/pre>
&lt;pre class="r">&lt;code>mc_int(s, n, mu = rep(0,5), sigma = diag(5))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 0.03162326&lt;/code>&lt;/pre>
&lt;pre class="r">&lt;code>mc_int(s, n, mu = rep(0,5), sigma = diag(5))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] -0.1287932&lt;/code>&lt;/pre>
&lt;pre class="r">&lt;code>mc_int(s, n, mu = rep(0,5), sigma = diag(5))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 0.01040134&lt;/code>&lt;/pre>
&lt;pre class="r">&lt;code>mc_int(s, n, mu = rep(0,5), sigma = diag(5))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] -0.03798655&lt;/code>&lt;/pre>
&lt;p>In the third case, there is a &lt;span class="math inline">\(-12\%\)&lt;/span> error(!) in the value of the computed integral when compared to the result from the SG approach. The SG approach, in addition, shows no such variation in repeated runs, since the grid values and weights are fixed for a given accuracy level and dimension (of the variable being integrated).&lt;/p>
&lt;p>I repeat the calculations for the second integral, as shown below&lt;/p>
&lt;p>MC approach:&lt;/p>
&lt;pre class="r">&lt;code>set.seed(100)
n &amp;lt;- 1000
mc_val &amp;lt;- mc_int(p, n, mu = rep(0,5), sigma = diag(5))
mc_val&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 1.001089&lt;/code>&lt;/pre>
&lt;p>SG approach:&lt;/p>
&lt;pre class="r">&lt;code>#generate sparse grids for a 5 dimensional RV with accuracy level 6
sg &amp;lt;- createSparseGrid(type=&amp;#39;KPN&amp;#39;, dimension=5, k=6)
sg_val &amp;lt;- sg_int(p, sg)
sg_val&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 1&lt;/code>&lt;/pre>
&lt;p>Once again, the SG approach gives us an exact value (note that the value of &lt;span class="math inline">\(k\)&lt;/span>, the accuracy level, has gone up, since the integrand is a higher order function). Again, the difference of the results between the two approaches doesn’t seem that large. However, variability of the results from the MC approach is still a concern, as shown below:&lt;/p>
&lt;pre class="r">&lt;code>set.seed(100)
mc_int(p, n, mu = rep(0,5), sigma = diag(5))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 1.001089&lt;/code>&lt;/pre>
&lt;pre class="r">&lt;code>mc_int(p, n, mu = rep(0,5), sigma = diag(5))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 0.4672555&lt;/code>&lt;/pre>
&lt;pre class="r">&lt;code>mc_int(p, n, mu = rep(0,5), sigma = diag(5))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 1.14692&lt;/code>&lt;/pre>
&lt;pre class="r">&lt;code>mc_int(p, n, mu = rep(0,5), sigma = diag(5))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 1.062975&lt;/code>&lt;/pre>
&lt;pre class="r">&lt;code>mc_int(p, n, mu = rep(0,5), sigma = diag(5))&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 0.9112416&lt;/code>&lt;/pre>
&lt;p>In the second case, there is a roughly &lt;span class="math inline">\(53\%\)&lt;/span> (!!) error when compared to the true value of the integral. This variability could be worse with more complicated integrands. One suggestion to reduce variability in MC methods is to increase the number of draws, but that would entail a lot of calculations and result in longer runtimes.&lt;/p>
&lt;p>To conclude, we have shown with this simple example how results from numerical integration using MC methods have high variability, and more often than not, it would be good idea to increase the number of draws being used to approximate an integral, or use a different method altogether (SG).&lt;/p>
&lt;div id="references" class="section level2 unnumbered">
&lt;h2>References&lt;/h2>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-mvt" class="csl-entry">
Genz, Alan, Frank Bretz, Tetsuhisa Miwa, Xuefei Mi, Friedrich Leisch, Fabian Scheipl, and Torsten Hothorn. 2019. &lt;em>&lt;span class="nocase">mvtnorm&lt;/span>: Multivariate Normal and t Distributions&lt;/em>. &lt;a href="https://CRAN.R-project.org/package=mvtnorm">https://CRAN.R-project.org/package=mvtnorm&lt;/a>.
&lt;/div>
&lt;div id="ref-heiss2008likelihood" class="csl-entry">
Heiss, Florian, and Viktor Winschel. 2008. &lt;span>“Likelihood Approximation by Numerical Integration on Sparse Grids.”&lt;/span> &lt;em>Journal of Econometrics&lt;/em> 144 (1): 62–80.
&lt;/div>
&lt;div id="ref-skrainka2011high" class="csl-entry">
Skrainka, Benjamin S, and Kenneth L Judd. 2011. &lt;span>“High Performance Quadrature Rules: How Numerical Integration Affects a Popular Model of Product Differentiation.”&lt;/span> &lt;em>Available at SSRN 1870703&lt;/em>.
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>The Homotopy Principle: Simple Examples</title><link>https://jmodeler.github.io/post/the-homotopy-principle-simple-examples/</link><pubDate>Mon, 20 Mar 2023 00:00:00 +0000</pubDate><guid>https://jmodeler.github.io/post/the-homotopy-principle-simple-examples/</guid><description>
&lt;p>This post presents 2 simple examples of the homotopy principle applied to (fairly easy) linear and nonlinear systems of equations. At a very abstract level, given a system of equations for which a solution is needed, we convert this system to one whose solution we already know (or is easy to find out), and then bend this system till we get the solution to the original set of equations. These methods have very broad applications &lt;span class="citation">(&lt;a href="#ref-garciapathways" role="doc-biblioref">Garcia and Zangwill 1981&lt;/a>)&lt;/span>, and have been applied in the context of finding equlibria in Static Games &lt;span class="citation">(&lt;a href="#ref-Bajari2010" role="doc-biblioref">Bajari et al. 2010&lt;/a>)&lt;/span> and Dynamic Games &lt;span class="citation">(&lt;a href="#ref-Borkovsky2010" role="doc-biblioref">Borkovsky, Doraszelski, and Kryukov 2010&lt;/a>)&lt;/span>.&lt;/p>
&lt;div id="example-1-linear-system" class="section level2">
&lt;h2>Example 1: Linear System&lt;/h2>
&lt;p>Say we want to find the solution to the following system of linear equations:
&lt;span class="math display" id="eq:linEx1">\[\begin{align}
\left[ \begin{array}
{rrrrr}
1 &amp;amp; 2 \\
3 &amp;amp; 4 \\
\end{array}\right] \left[ \begin{array} {r}
x_1 \\
x_2 \\
\end{array} \right] = \left[ \begin{array} {l}
5 \\
11 \\
\end{array} \right] \tag{1}
\end{align}\]&lt;/span>&lt;/p>
&lt;p>Readers should very easily be able to verify that the unique solution to this system is
&lt;span class="math display">\[
(x_1,x_2) = (1,2)
\]&lt;/span>&lt;/p>
&lt;p>Let’s convert this system and introduce an additional parameter &lt;span class="math inline">\(t\)&lt;/span>, called the &lt;em>homotopy parameter&lt;/em>, which varies from &lt;span class="math inline">\(0\)&lt;/span> to &lt;span class="math inline">\(1\)&lt;/span>. Let’s call this new system &lt;span class="math inline">\(H(x_1, x_2, t)\)&lt;/span>
&lt;span class="math display" id="eq:HFunc">\[\begin{align}
\left[ \begin{array}
{rr}
1 &amp;amp; 2 \\
3 &amp;amp; 4 \\
\end{array}\right] \left[ \begin{array} {r}
x_1 \\
x_2 \\
\end{array} \right] = \left[ \begin{array} {l}
5t \\
11t \\
\end{array} \right] \tag{2}
\end{align}\]&lt;/span>&lt;/p>
&lt;p>When &lt;span class="math inline">\(t=0\)&lt;/span>, &lt;span class="math inline">\(H(x_1, x_2, 0)\)&lt;/span> yields the trivial (and only) solution &lt;span class="math inline">\((x_1,x_2) = (0,0)\)&lt;/span>. When &lt;span class="math inline">\(t=1\)&lt;/span>, we get our original system of equations back. When we solve for &lt;span class="math inline">\((x_1, x_2)\)&lt;/span> as a function of &lt;span class="math inline">\(t\)&lt;/span>, we get:
&lt;span class="math display">\[
(x_1(t),x_2(t)) = (t,2t)
\]&lt;/span>
At &lt;span class="math inline">\(t=1\)&lt;/span>, this will give us the solution we desire. Tracing the path of the solution gives us the following plots:
&lt;img src="https://jmodeler.github.io/post/the-homotopy-principle-simple-examples/index.en_files/figure-html/unnamed-chunk-1-1.png" width="672" />&lt;/p>
&lt;p>&lt;img src="https://jmodeler.github.io/post/the-homotopy-principle-simple-examples/index.en_files/figure-html/unnamed-chunk-2-1.png" width="672" />&lt;/p>
&lt;p>&lt;img src="https://jmodeler.github.io/post/the-homotopy-principle-simple-examples/index.en_files/figure-html/unnamed-chunk-3-1.png" width="672" />&lt;/p>
&lt;p>From this very simple example, we note that the general process followed is given below &lt;span class="citation">(&lt;a href="#ref-garciapathways" role="doc-biblioref">Garcia and Zangwill 1981&lt;/a>)&lt;/span>:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>Convert the system of equations into one that has a known solution (i.e. &lt;span class="math inline">\(H(x_1, x_2, 0)\)&lt;/span> case above)&lt;/li>
&lt;li>Introduce a new parameter &lt;span class="math inline">\(t\)&lt;/span>, that gives the known system at &lt;span class="math inline">\(t=0\)&lt;/span> and the system for which the solutions are desired when &lt;span class="math inline">\(t=1\)&lt;/span>&lt;/li>
&lt;li>Trace the path of the solutions by changing the value of &lt;span class="math inline">\(t\)&lt;/span> from &lt;span class="math inline">\(0\)&lt;/span> to &lt;span class="math inline">\(1\)&lt;/span>&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div id="example-2-nonlinear-system" class="section level2">
&lt;h2>Example 2: Nonlinear System&lt;/h2>
&lt;p>Consider the following system of equations (from chapter 1, exercise 6 of &lt;span class="citation">(&lt;a href="#ref-garciapathways" role="doc-biblioref">Garcia and Zangwill 1981&lt;/a>)&lt;/span>):
&lt;span class="math display" id="eq:nonlinEx1">\[\begin{align}
F(x_1, x_2) =
\left[ \begin{array}
{l}
e^{2 x_1} - x^{2}_{2} + 3 \\
4x_{2}e^{2 x_1} - x^{3}_{2} \\
\end{array} \right]
= \left[ \begin{array} {l}
0 \\
0 \\
\end{array} \right] \tag{3} \\
(x_1, x_2) \in \mathbb{R}^2 \\
F: \mathbb{R}^2 \rightarrow \mathbb{R}^2
\end{align}\]&lt;/span>&lt;/p>
&lt;p>Again, readers should verify that the solutions to this system of equations are &lt;span class="math inline">\((x1, x2) = (0, -2) \, \&amp;amp; \, (x1, x2) = (0, 2)\)&lt;/span>.&lt;/p>
&lt;p>We now introduce the homotopy parameter &lt;span class="math inline">\(t\)&lt;/span>, and define &lt;span class="math inline">\(H(x_1, x_2, t)\)&lt;/span> as:&lt;/p>
&lt;p>&lt;span class="math display" id="eq:HfuncNonlin1">\[\begin{align}
H(x_1, x_2, t) = F(x_1, x_2) - (1-t)F(0, 0) \tag{4}
\end{align}\]&lt;/span>&lt;/p>
&lt;p>The formulation in &lt;a href="#eq:HfuncNonlin1">(4)&lt;/a> is called the &lt;em>Newton Homotopy&lt;/em> &lt;span class="citation">(&lt;a href="#ref-garciapathways" role="doc-biblioref">Garcia and Zangwill 1981&lt;/a>)&lt;/span>. A distinct advantage of this formulation, is that at &lt;span class="math inline">\(t=0\)&lt;/span>, it is easy to see that the solution to the system is &lt;span class="math inline">\((0, 0)\)&lt;/span>.&lt;/p>
&lt;p>For any &lt;span class="math inline">\(t\)&lt;/span> between &lt;span class="math inline">\(0\)&lt;/span> and &lt;span class="math inline">\(1\)&lt;/span>, &lt;span class="math inline">\(H(x_1, x_2, t)\)&lt;/span> becomes:
&lt;span class="math display" id="eq:HfuncNonlin2">\[\begin{align}
\left[ \begin{array}
{l}
e^{2 x_1} - x^{2}_{2} + 4t - 1 \\
4x_{2}e^{2 x_1} - x^{3}_{2} \\
\end{array} \right]
= \left[ \begin{array} {l}
0 \\
0 \\
\end{array} \right]
\tag{5}
\end{align}\]&lt;/span>&lt;/p>
&lt;p>We now attempt to find &lt;span class="math inline">\((x_1, x_2)\)&lt;/span> as functions of &lt;span class="math inline">\(t\)&lt;/span>. From &lt;a href="#eq:HfuncNonlin2">(5)&lt;/a>, we have:
&lt;span class="math display" id="eq:x2Sol">\[\begin{align}
x_{2}^{3} = 4x_{2}e^{2 x_1} \nonumber \\
x_2 = 0 \,\,\,\,\, OR \,\,\,\,\, x_{2} = \pm 2e^{x_1} \tag{6}
\end{align}\]&lt;/span>&lt;/p>
&lt;p>When &lt;span class="math inline">\(x_2 = 0\)&lt;/span>, putting this back in &lt;a href="#eq:HfuncNonlin2">(5)&lt;/a> we get:
&lt;span class="math display" id="eq:x1Sol1">\[\begin{align}
e^{2 x_1} + 4t - 1 = 0 \nonumber \\
\implies x_1 = \frac{1}{2} log(1-4t) \tag{7} \\
where \,\,\,\, 0 \le t \le 1/4
\end{align}\]&lt;/span>&lt;/p>
&lt;p>When &lt;span class="math inline">\(x_2 = \pm 2e^{x_1}\)&lt;/span>, putting this back in &lt;a href="#eq:HfuncNonlin2">(5)&lt;/a> we get:
&lt;span class="math display" id="eq:x1Sol2">\[\begin{align}
-3e^{2 x_1} + 4t - 1 = 0 \nonumber \\
\implies x_1 = \frac{1}{2} log\left(\frac{4t-1}{3}\right) \tag{8} \\
where \,\,\,\, 1/4 &amp;lt; t \le 1
\end{align}\]&lt;/span>&lt;/p>
&lt;p>Combining all the findings from &lt;a href="#eq:x2Sol">(6)&lt;/a>, &lt;a href="#eq:x1Sol1">(7)&lt;/a> and &lt;a href="#eq:x1Sol2">(8)&lt;/a>, we get:
&lt;span class="math display" id="eq:x2t" id="eq:x1t">\[\begin{align}
x_1(t) = \begin{cases}
\frac{1}{2} log(1-4t) &amp;amp; \text{for } 0\le t \le 1/4\\
\frac{1}{2} log\left(\frac{4t-1}{3}\right) &amp;amp; \text{for } 1/4 &amp;lt; t \leq 1
\end{cases} \tag{9} \\
x_1(t) = \begin{cases}
0 &amp;amp; \text{for } 0\le t \le 1/4\\
\pm 2 \sqrt{\left(\frac{4t-1}{3}\right)} &amp;amp; \text{for } 1/4 &amp;lt; t \leq 1
\end{cases} \tag{10}
\end{align}\]&lt;/span>&lt;/p>
&lt;p>Which gives us the solution to the system of equations in &lt;a href="#eq:nonlinEx1">(3)&lt;/a> at &lt;span class="math inline">\(t = 1\)&lt;/span>. However, note that the functions &lt;span class="math inline">\(x_1(t), x_2(t)\)&lt;/span> are non-differentiable, which disqualifies them from being solution paths &lt;span class="citation">(&lt;a href="#ref-garciapathways" role="doc-biblioref">Garcia and Zangwill 1981&lt;/a>)&lt;/span>. This is evident in the plots shown below:
&lt;img src="https://jmodeler.github.io/post/the-homotopy-principle-simple-examples/index.en_files/figure-html/unnamed-chunk-4-1.png" width="672" />&lt;/p>
&lt;p>&lt;img src="https://jmodeler.github.io/post/the-homotopy-principle-simple-examples/index.en_files/figure-html/unnamed-chunk-5-1.png" width="672" />&lt;/p>
&lt;p>One could always try another formulation for &lt;span class="math inline">\(H(x_1, x_2, t)\)&lt;/span> which leads to well defined paths to the desired solution from the known solution (i.e. the solution to &lt;span class="math inline">\(H(x_1, x_2, 0)\)&lt;/span>). That is left as an exercise to the reader.&lt;/p>
&lt;/div>
&lt;div id="references" class="section level2 unnumbered">
&lt;h2>References&lt;/h2>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-Bajari2010" class="csl-entry">
Bajari, Patrick, Han Hong, John Krainer, and Denis Nekipelov. 2010. &lt;span>“&lt;span class="nocase">Computing Equilibria in Static Games of Incomplete Information Using the All-Solution Homotopy&lt;/span>.”&lt;/span> &lt;em>Operations Research&lt;/em> 58 (4-part 2).
&lt;/div>
&lt;div id="ref-Borkovsky2010" class="csl-entry">
Borkovsky, Ron N., Ulrich Doraszelski, and Yaroslav Kryukov. 2010. &lt;span>“&lt;span class="nocase">A user’s guide to solving dynamic stochastic games using the homotopy method&lt;/span>.”&lt;/span> &lt;em>Operations Research&lt;/em> 58 (4 PART 2): 1116–32. &lt;a href="https://doi.org/10.1287/opre.1100.0843">https://doi.org/10.1287/opre.1100.0843&lt;/a>.
&lt;/div>
&lt;div id="ref-garciapathways" class="csl-entry">
Garcia, C B, and W I Zangwill. 1981. &lt;span>“&lt;span class="nocase">Pathways to solutions, fixed points, and equilibria. 1981&lt;/span>.”&lt;/span> Prentice-Hall, Englewood Cliffs, NJ.
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Completing Projects at Work</title><link>https://jmodeler.github.io/post/completing-projects-at-work/</link><pubDate>Sun, 19 Mar 2023 00:00:00 +0000</pubDate><guid>https://jmodeler.github.io/post/completing-projects-at-work/</guid><description>
&lt;p>This is a post inspired by a conversation I had with a colleague, Ryan. Over a very short period, he had completed an impressive portfolio of work projects, and always had something better in the pipeline. I asked him what he did when starting on anything, and he very kindly shared his method to get (most) things done at work (and in life, where applicable). In the following post, anything marked in &lt;span style="color: Tomato;"> tomato-red &lt;/span> is input from him.&lt;/p>
&lt;p>Ryan’s method to do anything in life (abstract version):&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>Determine what is being asked of you (or what you want to achieve). What problem are you trying to solve? Do not fall victim to the &lt;a href="https://en.wikipedia.org/wiki/XY_problem">XY problem&lt;/a>, be very clear about the deliverable expected. Check and re-check (or re-assess, in case this is a personal goal) with your boss/business partner/end goal &lt;span style="color: Tomato;">regularly&lt;/span>.&lt;/p>&lt;/li>
&lt;li>&lt;p>With a clear deliverable in mind, now clearly formulate the steps to be taken to get closer to said deliverable&lt;/p>&lt;/li>
&lt;li>&lt;p>Now, do you have all the skills/knowledge to do the steps yourself? Great! Make a plan to work on each step and stick to it. &lt;span style="color: Tomato;">Try to make a plan on how much work will be required time wise to progress through each step. This will also help you learn how good (or bad) you are at estimating time/specific tasks.&lt;/span>
&lt;span style="color: Tomato;"> I highly recommend reading &lt;a href="https://archive.fo/kHhdM">this blog post&lt;/a> about what to tackle first. He recommends basically making the smallest version of what you need that includes all the component parts. This helps you discover compatibility/integration issues up front that can wreck a project if they’re discovered late.&lt;br />
&lt;/span>&lt;/p>&lt;/li>
&lt;li>&lt;p>If you see there are gaps in your knowledge, you have two options:&lt;/p>
&lt;ul>
&lt;li>Learn everything you need to know to plug the knowledge gap (&lt;span style="color: Tomato;">generally terrifying and not recommended&lt;/span>)&lt;/li>
&lt;li>Find someone else who had the same problem and try to replicate what they’ve done. Google is your friend! (&lt;span style="color: Tomato;">generally where I start, using a &lt;a href="https://archive.fo/x5C54">tracer bullet&lt;/a>&lt;/span>). Once you’ve found a solution, follow the process outlined in step 3. and make progress on your work.&lt;/li>
&lt;/ul>&lt;/li>
&lt;li>&lt;p>As you keep working on your steps, DOCUMENT EVERYTHING. This will help you do the following:&lt;/p>
&lt;ul>
&lt;li>If you need to (or want to) move on to another project, you can hand this over to someone else and easily create a succession plan.&lt;/li>
&lt;li>If this project is a personal goal, you have a record of what you did. This will serve as a reference when you need to redo something like this in the future.&lt;/li>
&lt;li>&lt;span style="color: Tomato;">If your memory is anything like mine, it’s not great and you work on a lot. Your own documentation will help you know why you did something&lt;/span>.&lt;/li>
&lt;li>&lt;span style="color: Tomato;">It helps guide others through how to learn a topic&lt;/span>.&lt;/li>
&lt;li>&lt;span style="color: Tomato;">It can serve as a record of what work was done which can be useful as an archive, or for ideas for other work. Was one process a nightmare that you spent half your time on? Maybe that should be tackled next&lt;/span>.&lt;/li>
&lt;/ul>&lt;/li>
&lt;/ol></description></item></channel></rss>