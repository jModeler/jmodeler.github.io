<!doctype html><html lang=en><head><title>Omitted Variables Bias -- Simple Example Proof · The Journeyman Modeler
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Journeyman Modeler"><meta name=description content="In this post, I derive the expression in equation (4) of (Rossi 2014), as shown in the screenshot below.


  Setup
  
    
    Link to heading
  

The author provides the following system of regression equations:
\begin{align} y = & \beta x + \alpha_y v + \epsilon_y \tag{1} \\ x = & \alpha_x v + \epsilon_x \tag{2} \\ E(\epsilon_y|x, v) = & 0 \,\, \& \,\, E(\epsilon_x|x, v) = 0 \,\, \& \,\, \epsilon_y \perp\!\!\!\perp \epsilon_x \tag{3} \end{align}"><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Omitted Variables Bias -- Simple Example Proof"><meta name=twitter:description content="In this post, I derive the expression in equation (4) of (Rossi 2014), as shown in the screenshot below. Setup Link to heading The author provides the following system of regression equations:
\begin{align} y = & \beta x + \alpha_y v + \epsilon_y \tag{1} \\ x = & \alpha_x v + \epsilon_x \tag{2} \\ E(\epsilon_y|x, v) = & 0 \,\, \& \,\, E(\epsilon_x|x, v) = 0 \,\, \& \,\, \epsilon_y \perp\!\!\!\perp \epsilon_x \tag{3} \end{align}"><meta property="og:url" content="http://jmodeler.github.io/posts/2025-05-18-omitted-variables-bias-simple-example-proof/"><meta property="og:site_name" content="The Journeyman Modeler"><meta property="og:title" content="Omitted Variables Bias -- Simple Example Proof"><meta property="og:description" content="In this post, I derive the expression in equation (4) of (Rossi 2014), as shown in the screenshot below. Setup Link to heading The author provides the following system of regression equations:
\begin{align} y = & \beta x + \alpha_y v + \epsilon_y \tag{1} \\ x = & \alpha_x v + \epsilon_x \tag{2} \\ E(\epsilon_y|x, v) = & 0 \,\, \& \,\, E(\epsilon_x|x, v) = 0 \,\, \& \,\, \epsilon_y \perp\!\!\!\perp \epsilon_x \tag{3} \end{align}"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-18T00:00:00+00:00"><meta property="article:modified_time" content="2025-05-18T00:00:00+00:00"><meta property="article:tag" content="Regression"><meta property="article:tag" content="Statistics"><meta property="article:tag" content="Endogeneity"><link rel=canonical href=http://jmodeler.github.io/posts/2025-05-18-omitted-variables-bias-simple-example-proof/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.38c4552ac40f9ae3408bad40358f654ebd8804412fe74ed56f2d6c8a7af82dd3.css integrity="sha256-OMRVKsQPmuNAi61ANY9lTr2IBEEv507Vby1sinr4LdM=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=http://jmodeler.github.io/>The Journeyman Modeler
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/about/>About</a></li><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li></ul></section><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=http://jmodeler.github.io/posts/2025-05-18-omitted-variables-bias-simple-example-proof/>Omitted Variables Bias -- Simple Example Proof</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2025-05-18T00:00:00Z>May 18, 2025
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
5-minute read</span></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/regression/>Regression</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/statistics/>Statistics</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/endogeneity/>Endogeneity</a></span></div></div></header><div class=post-content><p>In this post, I derive the expression in equation (4) of (<a href=#ref-rossi2014iv>Rossi 2014</a>), as shown in the screenshot below.
<img src=/posts/2025-05-18-omitted-variables-bias-simple-example-proof/eq_4.png alt="Equation 4 from Rossi Paper"></p><h3 id=setup>Setup
<a class=heading-link href=#setup><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>The author provides the following system of regression equations:</p><p><code>\begin{align} y = & \beta x + \alpha_y v + \epsilon_y \tag{1} \\ x = & \alpha_x v + \epsilon_x \tag{2} \\ E(\epsilon_y|x, v) = & 0 \,\, \& \,\, E(\epsilon_x|x, v) = 0 \,\, \& \,\, \epsilon_y \perp\!\!\!\perp \epsilon_x \tag{3} \end{align}</code></p><p>In the above equations:</p><ol><li><p><a name=mean></a><code>\(y, x, v, \epsilon_y, \epsilon_x\)</code> are <code>\(n \, \times \, 1\)</code> vectors, where <code>\(n\)</code> is the number of data points. They are all assumed to be mean zero.</p></li><li><p><a name=variance></a><code>\(\epsilon_{x,i} \sim N(0, \sigma_{\epsilon_x}^2)\)</code>, <code>\(v_i \sim N(0, \sigma_v^2)\)</code></p></li><li><p><code>\(E\)</code> is the <a href=https://en.wikipedia.org/wiki/Expected_value class=external-link target=_blank rel=noopener>expectation operator</a>.</p></li><li><p>From standard results (in the equations below, <code>\(x'\)</code> is the <a href=https://en.wikipedia.org/wiki/Transpose class=external-link target=_blank rel=noopener>transpose</a> of a vector <code>\(x\)</code>; <code>\(Var(v_i)\)</code> denotes the variance of the random variable <code>\(v_i\)</code>):</p><ul><li><code>\(Var(v_i) = E(v_i^2) - E(v_i)^2 = E(v_i^2)\)</code>, since <code>\(E(v_i) = 0\)</code> from <a href=#mean>1.</a></li><li><a name=vvar></a><code>\(Var(v) = \sigma_v^2\)</code> from <a href=#variance>2.</a> Hence <code>\(E(v_i^2) = \sigma_v^2\)</code>. Also, <code>\(E(v'v) = E(\sum\limits_{i=1}^{n} v_i^2) = \sum\limits_{i=1}^{n} E(v_i^2) = n\sigma_v^2\)</code></li><li><code>\(Var(\epsilon_{x,i}) = E(\epsilon_x'\epsilon_x) - E(\epsilon_x)'E(\epsilon_x) = E(\epsilon_x'\epsilon_x)\)</code>, since <code>\(E(\epsilon_x) = 0\)</code> from <a href=#mean>1.</a></li><li><a name=evar></a><code>\(Var(\epsilon_{x,i}) = \sigma_{\epsilon_x}^2\)</code> from <a href=#variance>2.</a> Hence <code>\(E(\epsilon_{x,i}^2) = \sigma_{\epsilon_x}^2\)</code>. Also, <code>\(E(\epsilon_x'\epsilon_x) = E(\sum\limits_{i=1}^{n} \epsilon_{x,i}^2) = \sum\limits_{i=1}^{n} E(\epsilon_{x,i}^2) = n\sigma_{\epsilon_x}^2\)</code></li></ul></li><li><p>The conditions from equation (3) give us the following identities:</p><ul><li><a name=xecorr></a><code>\(E(x'\epsilon_y) = E(\epsilon_y' x) = 0\)</code></li><li><a name=vecorr></a><code>\(E(v'\epsilon_x) = E(\epsilon_x' v) = 0\)</code></li><li><a name=vxcorr></a><code>\(E(x'v) = E(v'x) = E((\alpha_x v + \epsilon_x)'v) = \alpha_xE(v'v) + E(\epsilon_x'v) = n\alpha_x \sigma_v^2 + 0 = n\alpha_x \sigma_v^2\)</code> (from <a href=#vvar>4b</a> and <a href=#vecorr>5b</a>)</li></ul></li></ol><h3 id=omitting-v>Omitting <code>\(v\)</code>
<a class=heading-link href=#omitting-v><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>If we regress <code>\(y\)</code> on <code>\(x\)</code> only (<strong>omitting</strong> <code>\(v\)</code>), we have something like this:</p><p><code>\begin{align} y = \beta x + \epsilon_c \end{align}</code></p><p>Where <code>\(\epsilon_c\)</code> is the “composite error term” and from (1), we have <code>\(\epsilon_c = \alpha_y v + \epsilon_y\)</code>. The expected value of <code>\(y\)</code> given <code>\(x\)</code> (<code>\(E(y|x)\)</code>), is now:</p><p><code>\begin{align} E(y|x) = & E(\beta x | x) + E(\epsilon_c|x) \\ \implies E(y|x) = & \beta x + E(\alpha_y v + \epsilon_y|x) \end{align}</code></p><p>Where I use the fact that <code>\(E(\beta x | x) = \beta E(x|x) = \beta x\)</code> (since the expectation operator is a linear operator and <code>\(E(x|x) = x\)</code>). I find the value of the second term <code>\(E(\alpha_y v + \epsilon_y|x)\)</code>.</p><h3 id=conditional-expectation-of-the-composite-error-term>Conditional Expectation of the Composite Error Term
<a class=heading-link href=#conditional-expectation-of-the-composite-error-term><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>Let’s call <code>\(z = \alpha_y v + \epsilon_y\)</code>. By construction, <code>\(z\)</code> is an <code>\(n \times 1\)</code> vector. I now regress <code>\(z\)</code> on <code>\(x\)</code>, i.e.
<code>\begin{align} z = & \gamma x + \epsilon_z \\ \implies \epsilon_z = & z - \gamma x \end{align}</code></p><p>I want to choose <code>\(\gamma\)</code> in such a way that <code>\(E(\epsilon_z'\epsilon_z)\)</code> is minimized (ideally we want <code>\(E(\epsilon_z'\epsilon_z) = 0\)</code>). Said another way, we want to choose our coefficient <code>\(\gamma\)</code> so that the expected value of the sum of squared error terms <code>\(\epsilon_{z,i}\)</code> as close to <code>\(0\)</code> as possible (<code>\(0\)</code> the smallest value the sum of squared real numbers can take). When this is true, I have <code>\(E(z|x)= E(\alpha_y v + \epsilon_y|x) = \gamma x\)</code>. Since <code>\(\epsilon_z = z - \gamma x\)</code>, I have</p><p><code>\begin{align} E(\epsilon_z'\epsilon_z) = & E((z - \gamma x)'(z - \gamma x)) \\ \implies E(\epsilon_z'\epsilon_z) = & E(z'z - \gamma (x'z + z'x) + \gamma^2 x'x) \\ = & E(z'z) - \gamma E(x'z + z'x) + \gamma^2 E(x'x) \\ = & E(z'z) - 2 \gamma E(x'z) + \gamma^2 E(x'x) \tag{4} \end{align}</code></p><p>Where (4) follows from the fact that <code>\(x'z\)</code> is scalar (both are <code>\(n \times 1\)</code> vectors), so <code>\(x'z = z'x\)</code>; applying the expectation operator on both sides, I have <code>\(E(x'z) = E(z'x)\)</code>. I now take the partial derivative of (4) with respect to <code>\(\gamma\)</code>.</p><p><code>\begin{align} \frac{\partial E(\epsilon_z'\epsilon_z)}{\partial \gamma} = & \frac{\partial (E(z'z)}{\partial \gamma} - \frac{\partial (2 \gamma E(x'z))}{\partial \gamma} + \frac{\partial (\gamma^2 E(x'x))}{\partial \gamma} = 0 \\ \implies & 0 - 2E(x'z) + 2 \gamma E(x'x) = 0 \\ \implies & \gamma = \frac{E(x'z)}{E(x'x)} \tag{5} \end{align}</code></p><p>I now want to find the values of <code>\(E(x'z)\)</code> and <code>\(E(x'x)\)</code>, which is straightforward, as shown below:</p><p><code>\begin{align} E(x'z) = & E(x'(\alpha_y v + \epsilon_y)) \\ = & \alpha_y E(x'v) + E(x'\epsilon_y) \\ \implies E(x'z) = & n\alpha_y \alpha_x \sigma_v^2 + 0 = n\alpha_y \alpha_x \sigma_v^2 \tag{6} \end{align}</code>
Where I used the following results:</p><ol><li><code>\(E(x'\epsilon_y) = 0\)</code>, from <a href=#xecorr>5a</a></li><li><code>\(E(x'v) = n\alpha_x \sigma_v^2\)</code>, from <a href=#vxcorr>5c</a></li></ol><p><code>\begin{align} E(x'x) = & E((\alpha_x v + \epsilon_x)'(\alpha_x v + \epsilon_x)) \\ = & E(\alpha_x^2 v'v + \alpha_x \epsilon_x'v + \alpha_x v'\epsilon_x + \epsilon_x'\epsilon_x) \\ = & \alpha_x^2 E( v'v) + 2 \alpha_x E( \epsilon_x'v ) + E(\epsilon_x'\epsilon_x) \\ \implies E(x'x) = & n\alpha_x^2 \sigma_v^2 + n\sigma_{\epsilon_x}^2 \tag{7} \end{align}</code>
Where I used the following results:</p><ol><li><code>\(E(\epsilon_x'v) = 0\)</code>, from <a href=#vecorr>5b</a></li><li><code>\(E(v'v) = n\sigma_v^2\)</code>, from <a href=#vvar>4b</a></li><li><code>\(E(\epsilon_x'\epsilon_x) = n\sigma_{\epsilon_x}^2\)</code>, from <a href=#evar>4d</a></li></ol><p>From (5), (6) and (7), I have:
<code>\begin{align} \gamma = & \frac{E(x'z)}{E(x'x)} = \frac{n\alpha_y \alpha_x \sigma_v^2}{n(\alpha_x^2 \sigma_v^2 + \sigma_{\epsilon_x}^2)} = \frac{\alpha_y \alpha_x \sigma_v^2}{\alpha_x^2 \sigma_v^2 + \sigma_{\epsilon_x}^2} \\ E(z|x) = & E(\alpha_y v + \epsilon_y | x) = \gamma x = \frac{\alpha_y \alpha_x \sigma_v^2}{\alpha_x^2 \sigma_v^2 + \sigma_{\epsilon_x}^2} x \end{align}</code></p><p>Which completes the proof.</p><h3 id=conclusion>Conclusion
<a class=heading-link href=#conclusion><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>In this post, I derive the expression for the bias in the coefficient of <code>\(x\)</code>, when you regress <code>\(y\)</code> on <code>\(x\)</code> without including the other independent variable <code>\(v\)</code>. This is called the omitted variable bias, and depending on the nature of this bias, the regression could come back with spurious results, something I’ll discuss in another post.</p><h1 id=references>References
<a class=heading-link href=#references><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><div id=refs class="references csl-bib-body hanging-indent" entry-spacing=0><div id=ref-rossi2014iv class=csl-entry><p>Rossi, Peter E. 2014. “Even the Rich Can Make Themselves Poor: A Critical Examination of IV Methods in Marketing Applications.” <em>Marketing Science</em> 33 (5): 655–72. <a href=https://doi.org/10.1287/mksc.2014.0865 class=external-link target=_blank rel=noopener>https://doi.org/10.1287/mksc.2014.0865</a>.</p></div></div></div><footer></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>©
2023 -
2025
Journeyman Modeler
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>