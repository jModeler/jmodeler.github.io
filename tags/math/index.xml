<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Math on The Journeyman Modeler</title><link>http://jmodeler.github.io/tags/math/</link><description>Recent content in Math on The Journeyman Modeler</description><generator>Hugo</generator><language>en</language><lastBuildDate>Sat, 26 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://jmodeler.github.io/tags/math/index.xml" rel="self" type="application/rss+xml"/><item><title>Sample Size and Effect Size</title><link>http://jmodeler.github.io/posts/2025-04-26-sample-size-and-effect-size/</link><pubDate>Sat, 26 Apr 2025 00:00:00 +0000</pubDate><guid>http://jmodeler.github.io/posts/2025-04-26-sample-size-and-effect-size/</guid><description>&lt;p>In this post, I show how the sample size of the treatment and control samples in an A/B test affect the impact size. The assumption here is that the population variances of both samples are known, and the responses of the individual units in these samples are Independent and Identically Distributed (IID), which simplifies this demonstration.&lt;/p>
&lt;h3 id="setup">
 Setup
 &lt;a class="heading-link" href="#setup">
 &lt;i class="fa-solid fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
 &lt;span class="sr-only">Link to heading&lt;/span>
 &lt;/a>
&lt;/h3>
&lt;p>Let&amp;rsquo;s say the responses in the control sample are &lt;code>\(X_i \sim N(\mu_X, \sigma_X^2)\)&lt;/code> and the responses in the treatment sample are &lt;code>\(Y_i \sim N(\mu_Y, \sigma_Y^2)\)&lt;/code>. We want to check if the mean response of the treatment is significantly different from the mean response of the control sample (i.e. we want to check if &lt;code>\(\bar{Y} - \bar{X}\)&lt;/code> is statistically different from &lt;code>\(0\)&lt;/code>).&lt;/p></description></item><item><title>Distribution Of The Negative of A Normally Distributed Random Variable</title><link>http://jmodeler.github.io/posts/negative-normal-rv/</link><pubDate>Mon, 14 Apr 2025 00:00:00 +0000</pubDate><guid>http://jmodeler.github.io/posts/negative-normal-rv/</guid><description>&lt;p>This post derives the distribution for an random variable that appears in the derivation of a &lt;a href="https://jmodeler.github.io/posts/2025-04-26-sample-size-and-effect-size/" class="external-link" target="_blank" rel="noopener">result in another post&lt;/a>.&lt;/p>
&lt;p>In this post, I derive the distribution of the negative of a normally distributed random variable. Let&amp;rsquo;s say we have &lt;code>\(X \sim N(\mu, \sigma^2)\)&lt;/code>, and we want to find the distribution of &lt;code>\(Y=-X\)&lt;/code>.&lt;/p>
&lt;p>I start with the identity:
&lt;code>\begin{align} P(Y \le y) = P(-X \le y) = P(X \ge -y) = 1 - P(X \le -y) \end{align}&lt;/code>&lt;/p></description></item><item><title>Distribution of the Sample Mean of IID Normal Random Variables</title><link>http://jmodeler.github.io/posts/distribution-sample-mean/</link><pubDate>Mon, 14 Apr 2025 00:00:00 +0000</pubDate><guid>http://jmodeler.github.io/posts/distribution-sample-mean/</guid><description>&lt;p>In this post I derive a result that will be used in &lt;a href="https://jmodeler.github.io/posts/2025-04-26-sample-size-and-effect-size/" class="external-link" target="_blank" rel="noopener">another post&lt;/a>.&lt;/p>
&lt;p>Say we have Independent and Identically Distributed (IID) Normal random variables &lt;code>\(X_i \sim N(\mu, \sigma^2)\)&lt;/code>, and we have&lt;/p>
&lt;p>&lt;code>\begin{align} \bar{X} = \frac{1}{n}\sum^{n}_{i=1} X_i \end{align}&lt;/code>&lt;/p>
&lt;p>We want the distribution of &lt;code>\(\bar{X}\)&lt;/code>.&lt;/p>
&lt;p>From a &lt;a href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables" class="external-link" target="_blank" rel="noopener">standard result&lt;/a>, &lt;code>\(\bar{X}\)&lt;/code> is also Normally distributed. Once we have the mean and variance of &lt;code>\(\bar{X}\)&lt;/code>, we can completely specify its distribution.&lt;/p>
&lt;p>For the mean of &lt;code>\(\bar{X}\)&lt;/code>, note that &lt;code>\(E(X_i) = \mu\)&lt;/code> we then have:
&lt;code>\begin{align} E(\bar{X}) = &amp;amp; \frac{1}{n} E\left(\sum^{n}_{i=1} X_i \right) \\ = &amp;amp; \frac{1}{n} \left(\sum^{n}_{i=1} E(X_i) \right) \\ = &amp;amp; \frac{1}{n} n\mu = \mu \end{align}&lt;/code>&lt;/p></description></item><item><title>A Summation Formula</title><link>http://jmodeler.github.io/posts/a-summation-formula/</link><pubDate>Mon, 07 Apr 2025 00:00:00 +0000</pubDate><guid>http://jmodeler.github.io/posts/a-summation-formula/</guid><description>&lt;p>This post derives a closed form solution for particular sum that appears in the derivation of a result in &lt;a href="https://jmodeler.github.io/posts/distribution-sample-mean/" class="external-link" target="_blank" rel="noopener">another post&lt;/a>.&lt;/p>
&lt;p>Say we have real numbers &lt;code>\(X_i\)&lt;/code> such that
&lt;code>\begin{align} X_i = x \,\, \forall i \tag{1} \end{align}&lt;/code>&lt;/p>
&lt;p>And we want to find the sum
&lt;code>\begin{align} \mathop{\sum\sum}_{\substack{i \ne j}} X_i X_j \,\,\,\, i,j \in {1, 2, \dots , n} \tag{2} \end{align}&lt;/code>&lt;/p>
&lt;p>From (1), the sum in (2) boils down to:
&lt;code>\begin{align} \mathop{\sum\sum}_{\substack{i \ne j}} x^2 \tag{3} \end{align}&lt;/code>&lt;/p></description></item></channel></rss>